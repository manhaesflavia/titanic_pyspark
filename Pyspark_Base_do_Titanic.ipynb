{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VVhftde2rAKIX0SUORE7SKaKIOMbF-Ad",
      "authorship_tag": "ABX9TyNcyq6ZYuxUXxBVRcej8p+/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manhaesflavia/titanic_pyspark/blob/main/Pyspark_Base_do_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Um empresário do ramo de cruzeiros está procurando expandir seus negócios, mas precisa entender melhor seu público-alvo. Ele tem em mãos os dados do \"Titanic - Machine Learning from Disaster\", que contém informações sobre passageiros do navio Titanic. Com base nesses dados, o empresário pode tomar decisões mais informadas sobre como atrair e atender melhor seus clientes:\n",
        "\n",
        "\n",
        "1.  O empresário quer saber se há alguma correlação entre a idade dos passageiros do Titanic e a classe em que estavam viajando. Ele gostaria de saber se os passageiros mais velhos tendiam a viajar em classes superiores ou inferiores. Como você poderia ajudá-lo a responder essa pergunta utilizando o conjunto de dados do Titanic?\n",
        "\n",
        "\n",
        "\n",
        "2.  O empresário está interessado em criar um programa de fidelidade para seus clientes, mas não tem certeza de qual abordagem seria mais eficaz. Ele gostaria de saber se há alguma relação entre o gênero dos passageiros do Titanic e a sobrevivência no navio.\n",
        "\n",
        "\n",
        "\n",
        "3.  Qual a probabilidade de sobrevivência de um passageiro de primeira classe com menos de 20 anos?\n",
        "\n",
        "\n",
        "\n",
        "4.  Quais as principais características em comum entre os sobreviventes do desastre do Titanic?\n",
        "\n",
        "\n",
        "\n",
        "5.  É possível identificar alguma correlação entre a idade e a taxa de sobrevivência dos passageiros que embarcaram em Southampton?\n",
        "\n"
      ],
      "metadata": {
        "id": "6rQaR8NsocvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5fBIC6hGo3bl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalações"
      ],
      "metadata": {
        "id": "bn-vYwW9pBi2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_9I63ieFoSbM",
        "outputId": "422188d5-ec42-4561-e1f5-821914253bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.3.2\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5 (from pyspark==3.3.2)\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824006 sha256=730d74278e91476fb8e974fd7383a3015ef4a2058df76609a9cc886936620cfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/d6/52/1178e354ba2207673484f0ccd7b2ded0ab6671ae5c1fc5b49a\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 3.5.3\n",
            "    Uninstalling pyspark-3.5.3:\n",
            "      Successfully uninstalled pyspark-3.5.3\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.3.2\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = (\n",
        "    SparkSession.builder.appName(\"Titanic - Compreensão do publico alvo\").config('spark.sql.repl.eagerEval.enabled', True).getOrCreate()\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "eMi1ZQaBrEZd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importes"
      ],
      "metadata": {
        "id": "WFFM8MM6pNre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_gender_submission = spark.read.csv(r'/content/drive/MyDrive/Cursos/PySpark/titanic/gender_submission.csv', sep = ',', header = True)\n",
        "df_test = spark.read.csv(r'/content/drive/MyDrive/Cursos/PySpark/titanic/test.csv', sep = ',', header = True)\n",
        "df_train = spark.read.csv(r'/content/drive/MyDrive/Cursos/PySpark/titanic/train.csv', sep = ',', header = True)\n"
      ],
      "metadata": {
        "id": "k9dOgPX0pPMq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## 1) O empresário quer saber se há alguma **correlação entre a idade dos passageiros do Titanic e a classe em que estavam viajando**.\n",
        "\n",
        "Ele gostaria de saber se os passageiros mais velhos tendiam a viajar em classes superiores ou inferiores.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FOJzMjvdsrqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para a resolução será necessário unir os dados de treino e testes, para ter os dados completos da base de dados do titanic. Neste caso, a coluna 'survived' não será utilizada."
      ],
      "metadata": {
        "id": "doQYs7Z6tF4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Numero de linhas e colunas de df_test\n",
        "print(\"df_test\")\n",
        "print(\"rows: \", df_test.count())\n",
        "print(\"columns: \", len(df_test.columns))\n",
        "print(\"\\n\")\n",
        "\n",
        "# ---- Numero de linhas de df_train\n",
        "print(\"df_train\")\n",
        "print(\"rows: \", df_train.count())\n",
        "print(\"columns: \", len(df_train.columns))\n",
        "print(\"\\n\")\n",
        "# ---- unionByName para concatenar dois dataframes pyspark, esse método concatena os dataframes baseado no nome da coluna\n",
        "\n",
        "# Uso do drop no dataframe para remover a coluna 'Survived'.\n",
        "df_titanic_complete = df_train.drop('Survived').unionByName(df_test)\n",
        "\n",
        "# ---- Numero de linhas de df_titanic_complete\n",
        "print(\"df_titanic_complete\")\n",
        "print(\"rows: \", df_titanic_complete.count())\n",
        "print(\"columns: \", len(df_titanic_complete.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wLQCtyArf_I",
        "outputId": "addab2d7-450b-450b-97d3-24f07ffcd78e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_test\n",
            "rows:  418\n",
            "columns:  11\n",
            "\n",
            "\n",
            "df_train\n",
            "rows:  891\n",
            "columns:  12\n",
            "\n",
            "\n",
            "df_titanic_complete\n",
            "rows:  1309\n",
            "columns:  11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para avaliar qual método de correlação adequado"
      ],
      "metadata": {
        "id": "pcMFEgeOw4UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Para avaliar qua"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "Du7NMX4Ot-Fo",
        "outputId": "9cd863ed-6b35-4b7a-e75c-ceeb8d255be7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[PassengerId: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string]"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>PassengerId</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr>\n",
              "<tr><td>1</td><td>3</td><td>Braund, Mr. Owen ...</td><td>male</td><td>22</td><td>1</td><td>0</td><td>A/5 21171</td><td>7.25</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>2</td><td>1</td><td>Cumings, Mrs. Joh...</td><td>female</td><td>38</td><td>1</td><td>0</td><td>PC 17599</td><td>71.2833</td><td>C85</td><td>C</td></tr>\n",
              "<tr><td>3</td><td>3</td><td>Heikkinen, Miss. ...</td><td>female</td><td>26</td><td>0</td><td>0</td><td>STON/O2. 3101282</td><td>7.925</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>4</td><td>1</td><td>Futrelle, Mrs. Ja...</td><td>female</td><td>35</td><td>1</td><td>0</td><td>113803</td><td>53.1</td><td>C123</td><td>S</td></tr>\n",
              "<tr><td>5</td><td>3</td><td>Allen, Mr. Willia...</td><td>male</td><td>35</td><td>0</td><td>0</td><td>373450</td><td>8.05</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>6</td><td>3</td><td>Moran, Mr. James</td><td>male</td><td>null</td><td>0</td><td>0</td><td>330877</td><td>8.4583</td><td>null</td><td>Q</td></tr>\n",
              "<tr><td>7</td><td>1</td><td>McCarthy, Mr. Tim...</td><td>male</td><td>54</td><td>0</td><td>0</td><td>17463</td><td>51.8625</td><td>E46</td><td>S</td></tr>\n",
              "<tr><td>8</td><td>3</td><td>Palsson, Master. ...</td><td>male</td><td>2</td><td>3</td><td>1</td><td>349909</td><td>21.075</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>9</td><td>3</td><td>Johnson, Mrs. Osc...</td><td>female</td><td>27</td><td>0</td><td>2</td><td>347742</td><td>11.1333</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>10</td><td>2</td><td>Nasser, Mrs. Nich...</td><td>female</td><td>14</td><td>1</td><td>0</td><td>237736</td><td>30.0708</td><td>null</td><td>C</td></tr>\n",
              "<tr><td>11</td><td>3</td><td>Sandstrom, Miss. ...</td><td>female</td><td>4</td><td>1</td><td>1</td><td>PP 9549</td><td>16.7</td><td>G6</td><td>S</td></tr>\n",
              "<tr><td>12</td><td>1</td><td>Bonnell, Miss. El...</td><td>female</td><td>58</td><td>0</td><td>0</td><td>113783</td><td>26.55</td><td>C103</td><td>S</td></tr>\n",
              "<tr><td>13</td><td>3</td><td>Saundercock, Mr. ...</td><td>male</td><td>20</td><td>0</td><td>0</td><td>A/5. 2151</td><td>8.05</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>14</td><td>3</td><td>Andersson, Mr. An...</td><td>male</td><td>39</td><td>1</td><td>5</td><td>347082</td><td>31.275</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>15</td><td>3</td><td>Vestrom, Miss. Hu...</td><td>female</td><td>14</td><td>0</td><td>0</td><td>350406</td><td>7.8542</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>16</td><td>2</td><td>Hewlett, Mrs. (Ma...</td><td>female</td><td>55</td><td>0</td><td>0</td><td>248706</td><td>16</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>17</td><td>3</td><td>Rice, Master. Eugene</td><td>male</td><td>2</td><td>4</td><td>1</td><td>382652</td><td>29.125</td><td>null</td><td>Q</td></tr>\n",
              "<tr><td>18</td><td>2</td><td>Williams, Mr. Cha...</td><td>male</td><td>null</td><td>0</td><td>0</td><td>244373</td><td>13</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>19</td><td>3</td><td>Vander Planke, Mr...</td><td>female</td><td>31</td><td>1</td><td>0</td><td>345763</td><td>18</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>20</td><td>3</td><td>Masselmani, Mrs. ...</td><td>female</td><td>null</td><td>0</td><td>0</td><td>2649</td><td>7.225</td><td>null</td><td>C</td></tr>\n",
              "</table>\n",
              "only showing top 20 rows\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}